<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <title>Entrainement des IA</title>
    <link rel="stylesheet" href="../styles.css">

</head>
<body>

<header>
    <h1>Optimisation des calculs GPU</h1>
    <nav>
        <a href="index.html">Retour à l'accueil</a>
    </nav>
</header>

<main>
    <p>Quand on parle de modèle d'IA et de deep learning et de leur impact, on parle rapidement de la consommation d'un GPU. Si vous n'avez pas encore lu la partie <a href="../motivations/why.html">motivations</a>, il est préférable de la lire avant cette partie afin de comprendre l'impact que peu avoir les GPUs d'un point de vu environnemental.
    </p>

    <p>
        L'utilisation des unités de traitement graphique (GPU) dans l'entraînement de modèles d'intelligence artificielle a considérablement transformé la manière dont on abordent les problèmes complexes. Les GPU, initialement conçus pour les tâches de rendu graphique, se sont révélés être des accélérateurs puissants pour les calculs parallèles nécessaires à l'entraînement de modèles d'apprentissage profond. L'un des principaux avantages des GPU réside dans leur capacité à traiter simultanément de multiples opérations, accélérant ainsi de manière significative les calculs nécessaires à l'ajustement des poids dans un réseau de neurones, l'entrainement.
    </p>
    <p>
        Les architectures parallèles des GPU permettent de répartir les calculs sur un grand nombre de cœurs, ce qui rend l'entraînement de modèles massivement parallélisable. Contrairement aux processeurs centraux (CPU) traditionnels, les GPU excèdent en termes de puissance de calcul brute, ce qui se traduit par des temps d'entraînement réduits. Cette accélération est particulièrement cruciale dans le contexte de l'apprentissage profond, où des modèles complexes nécessitent souvent des millions, voire des milliards, de paramètres à ajuster.
    </p>
    <!-- Ajoutez ici vos explications sur l'entraînement des IA -->

    <p> Sources :
        <ul>
            <li> YOU, Jie, CHUNG, Jae-Won, et CHOWDHURY, Mosharaf. Zeus: Understanding and Optimizing {GPU} Energy Consumption of {DNN} Training. In : 20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23). 2023. p. 119-139. <a href="https://www.usenix.org/system/files/nsdi23-you.pdf">papier</a></li>
        </ul>

    </p>
</main>

<footer>
    <p>&copy; 2024 Elouan Vincent</p>
</footer>

</body>
</html>
