<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <title>Entrainement des IA</title>
    <link rel="stylesheet" href="../styles.css">

</head>
<body>

<header>
    <h1>Entrainement d'un modèle</h1>
    <nav>
        <a href="index.html">Retour à la mindmap</a>
    </nav>
</header>

<main>
    <p>Ce qu'on appelle "entraînement du modèle", c'est le moment où le modèle va voir les données, faire une prédiction, puis minimiser une fonction de coût (dans le cas supervisé, on connaît le label ou la target d'une instance, par exemple, dans une tâche de classification de chien et de chat, je sais qu'une image x contient un chat.).
        Souvent, le modèle va voir plusieurs fois les données. A chaque fois, il va modifier ses paramètres internes de sorte à améliorer ses résultats, c'est-à-dire en minimisant la fonction de coût.
        L'entraînement d'un modèle peut prendre plus ou moins de temps selon la dimension des données, leur nombre, la complexité du modèle et aussi le nombre de fois que l'on souhaite que le modèle voie les données.
    </p>
    <p> 
        En plus de ça, pour obtenir les meilleurs modèles possible, il y a souvent une étape qu'on appelle le "fine-tuning". Cette étape concerne les hyperparamètres. Contrairement aux paramètres internes du modèle dont on parlait précédemment, qui sont eux, modifier pendant l'étape d'apprentissage,
        les hyperparamètres sont des paramètres qui définissent la structure du modèle, par exemple le nombre de couches, la taille des couches, mais aussi l'algorithme d'optimisation, le pas d'apprentissage et plein d'autres choses.
        Ces hyperparamètres, c'est à l'humain de les fixer, et il n'est pas rare de voir une combinaison d'hyperparamètres sous-performer.
        L'étape de "fine-tuning" est donc l'étape où l'on va essayer de trouver la meilleure combinaison d'hyperparamètres pour un modèle et un tâche précise.
        Comme il n'y a pas d'ensemble d'hyperparamètres qui marche pour tous les modèles et toutes les tâches, il faut donc réessayer à chaque nouvelle problématique.
        Le but est donc d'essayer plusieurs combinaisons d'hyperparamètres, et de choisir celle qui donne les meilleurs résultats, pour cela, pour chaque combinaison, on entraîne le modèle en entier. Enfin, on compare les modèles sur un ensemble de données
        de validation, et on choisit le modèle qui donne les meilleurs résultats.
    </p>
    <p>    
        L'étape de fine-tuning peut donc être extrêmement coûteuse. Pour les modèles très lourds, il est déjà très long de faire un entraînement,
        entraîner plusieurs modèles pour le "fine-tuning" peut être extrement long, monopoliser des ressources pendant plusieurs semaines voir mois.
    </p>
    <p>    
        Ce qu'il faut voir, c'est ce que l'on gagne en faisant du "fine-tuning". Parfois, on aura un gain de performance énorme en trouvant la bonne combinaison d'hyperparamètre.
        En revanche, il n'est pas rare d'avoir un écart très faible entre le premier modèle et celui qu'on a obtenu avec le "fine-tuning". Dans ce cas, on a utilisé beaucoup de ressources pour
        un gain faible.
    </p>
    <p>    
        Il faut donc trouver un compromis entre le temps d'entraînement et le gain de performance. C'est ce qu'on appelle souvent le "trade-off".
        La question qu'on doit se poser, c'est est-ce que j'ai vraiment besoin de gagner 0.1% de performance en plus ? Dans certains cas, la réponse est rapidement oui,
        mais dans d'autres, la question mérite d'être posée. Il y a des situations où l'utilisateur final ne verra pas la différence entre un modèle qui a 90% de précision et un modèle qui a 90.1% de précision.
        Et éventuellement, l'impact de l'erreur du modèle peu être faible. Par example, si on fait un modèle qui détecte des tumeurs dans des IRMs, on veut forcément que le modèle rate le moins de tumeur possible et qu'il les segmente de la manière la plus précise possible.
        En revanche, si le but est de compter le nombre de grain de riz dans un sac, on peut se permettre d'avoir un modèle qui se trompe de temps en temps, car l'impact de l'erreur est faible.
    </p>
    <p>    
        Enfin, il existe des solutions pour rendre l'apprentissage plus léger (ou plutôt moins lourd) dans certaines situations spécifique. On abordera ces solutions plus tard dans cette veille, mais il faut aussi noter que les choix du modèle peuvent avoir une importance cruciale !</p>
    </p>
</main>

<footer>
    <p>&copy; 2024 Elouan Vincent</p>
</footer>

</body>
</html>
