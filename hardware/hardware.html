<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <title>Frugalité des IA</title>
    <link rel="stylesheet" href="../styles.css">

</head>
<body>

<header>
    <h1>Matériel pour les IA</h1>
    <nav>
        <a href="../index.html">Retour à l'accueil</a>
    </nav>
</header>

<main>
    <p>Le domaine du machine learning et du deep learning bénéficie d'une diversité croissante de matériels spécialisés 
        pour répondre aux exigences computationnelles de plus en plus complexes des modèles. Les processeurs centraux 
        (CPU) offrent une polyvalence générale et sont utilisés pour des tâches d'apprentissage de petite à moyenne 
        envergure. Cependant, le véritable essor réside dans l'utilisation d'unités de traitement graphique (GPU) 
        qui excelle dans le traitement parallèle et accélère significativement les calculs liés à l'entraînement de modèles. 
        Les GPU, popularisés par des entreprises telles que NVIDIA, sont devenus un choix incontournable pour le deep learning. 
        De plus, des architectures de processeurs spécifiques, comme les unités de traitement tensoriel (TPU) développées par 
        Google, ont émergé pour optimiser les opérations spécifiques aux réseaux de neurones. 
        Les dispositifs FPGA (Field-Programmable Gate Arrays) permettent également une certaine flexibilité dans 
        la personnalisation matérielle pour des tâches spécifiques. Enfin, des solutions cloud intégrant des
        processeurs spécialisés, comme les instances GPU sur des plateformes telles qu'AWS, Azure, et Google Cloud, 
        offrent une flexibilité et une échelle inégalées pour les projets de machine learning et de deep learning à 
        grande envergure. L'évolution constante de ces technologies matérielles reflète la quête continue de 
        performances optimales dans le domaine en plein essor de l'intelligence artificielle.</p>

    <p> Si on veut réduire l'impact de nos modèles, on peut donc commencer par choisir de réduire l'impact des hardwares que l'on utilise.
        Le stockage des données, le CPU, la RAM, le GPU, et TPU, tout ces éléments ont un impact sur l'environnement.
        La première chose, c'est qu'ils dégagent de la chaleur. Un appareil qui dégage de la chaleur, c'est un appareil qui perd de l'énergie.
        L'énergie qu'il consomme n'est donc pas pleinement utilisée, et donc perdue. En plus, il faut refroidir ces appareils, et donc dépenser
         de l'énergie pour les refroidir.
        On voit rapidement que pour réduire la consommation lié à un modèle, on peut commencer par réduire la consommation des
        ressources matérielles.

        Dans cette partie, on va parler un peu de comment on peut envisager de réduire la consommation de ressources matérielles, notamment du GPU, mais aussi évoqué le cloud computing.
    </p>
    <!-- Ajoutez ici vos explications sur le matériel pour les IA -->
</main>

<footer>
    <p>&copy; 2024 Elouan Vincent</p>
</footer>

</body>
</html>
